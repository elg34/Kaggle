{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 var: 256\n",
      "Corr>0.95: 139 Now:\n",
      "Corr Target <0.1: 4206\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "\n",
    "def drop_vars(df):\n",
    "    tmp=df.shape[1]\n",
    "    df = df[df.columns[[True]+list((df.var()!=0))]]\n",
    "    print('0 var:',tmp-df.shape[1])\n",
    "    \n",
    "    corr_matrix = df[df.columns[2:]].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    tmp=df.shape[1]\n",
    "    df=df.drop(to_drop, axis=1)\n",
    "    print('Corr>0.95:',tmp-df.shape[1],'Now:',)\n",
    "    \n",
    "    corrs = dict()\n",
    "    for i in range(df.shape[1]-2):\n",
    "        corrs[df.columns[2+i]] = np.corrcoef(df['target'],df[df.columns[2+i]])[0,1]\n",
    "    s = [k for k in corrs if abs(corrs[k])<0.1]\n",
    "    tmp=df.shape[1]\n",
    "    df=df.drop(s, axis=1)\n",
    "    print('Corr Target <0.1:',tmp-df.shape[1])\n",
    "    \n",
    "    return df\n",
    "train = drop_vars(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's rmse: 1.73905\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's rmse: 1.73622\n",
      "[3]\tvalid_0's rmse: 1.7331\n",
      "[4]\tvalid_0's rmse: 1.73015\n",
      "[5]\tvalid_0's rmse: 1.72709\n",
      "[6]\tvalid_0's rmse: 1.72404\n",
      "[7]\tvalid_0's rmse: 1.72075\n",
      "[8]\tvalid_0's rmse: 1.71815\n",
      "[9]\tvalid_0's rmse: 1.71527\n",
      "[10]\tvalid_0's rmse: 1.71258\n",
      "[11]\tvalid_0's rmse: 1.71013\n",
      "[12]\tvalid_0's rmse: 1.70768\n",
      "[13]\tvalid_0's rmse: 1.70481\n",
      "[14]\tvalid_0's rmse: 1.70174\n",
      "[15]\tvalid_0's rmse: 1.69912\n",
      "[16]\tvalid_0's rmse: 1.69655\n",
      "[17]\tvalid_0's rmse: 1.69368\n",
      "[18]\tvalid_0's rmse: 1.69111\n",
      "[19]\tvalid_0's rmse: 1.68873\n",
      "[20]\tvalid_0's rmse: 1.68614\n",
      "[21]\tvalid_0's rmse: 1.68322\n",
      "[22]\tvalid_0's rmse: 1.68106\n",
      "[23]\tvalid_0's rmse: 1.67854\n",
      "[24]\tvalid_0's rmse: 1.67562\n",
      "[25]\tvalid_0's rmse: 1.67322\n",
      "[26]\tvalid_0's rmse: 1.67093\n",
      "[27]\tvalid_0's rmse: 1.66864\n",
      "[28]\tvalid_0's rmse: 1.66628\n",
      "[29]\tvalid_0's rmse: 1.66408\n",
      "[30]\tvalid_0's rmse: 1.66164\n",
      "[31]\tvalid_0's rmse: 1.65921\n",
      "[32]\tvalid_0's rmse: 1.6569\n",
      "[33]\tvalid_0's rmse: 1.65467\n",
      "[34]\tvalid_0's rmse: 1.6525\n",
      "[35]\tvalid_0's rmse: 1.65035\n",
      "[36]\tvalid_0's rmse: 1.64817\n",
      "[37]\tvalid_0's rmse: 1.64639\n",
      "[38]\tvalid_0's rmse: 1.64398\n",
      "[39]\tvalid_0's rmse: 1.64191\n",
      "[40]\tvalid_0's rmse: 1.63966\n",
      "[41]\tvalid_0's rmse: 1.63764\n",
      "[42]\tvalid_0's rmse: 1.63577\n",
      "[43]\tvalid_0's rmse: 1.6338\n",
      "[44]\tvalid_0's rmse: 1.63185\n",
      "[45]\tvalid_0's rmse: 1.62953\n",
      "[46]\tvalid_0's rmse: 1.62739\n",
      "[47]\tvalid_0's rmse: 1.62506\n",
      "[48]\tvalid_0's rmse: 1.62295\n",
      "[49]\tvalid_0's rmse: 1.62077\n",
      "[50]\tvalid_0's rmse: 1.61904\n",
      "[51]\tvalid_0's rmse: 1.61713\n",
      "[52]\tvalid_0's rmse: 1.61506\n",
      "[53]\tvalid_0's rmse: 1.61324\n",
      "[54]\tvalid_0's rmse: 1.61176\n",
      "[55]\tvalid_0's rmse: 1.61014\n",
      "[56]\tvalid_0's rmse: 1.60815\n",
      "[57]\tvalid_0's rmse: 1.60644\n",
      "[58]\tvalid_0's rmse: 1.60451\n",
      "[59]\tvalid_0's rmse: 1.60281\n",
      "[60]\tvalid_0's rmse: 1.60125\n",
      "[61]\tvalid_0's rmse: 1.59967\n",
      "[62]\tvalid_0's rmse: 1.59825\n",
      "[63]\tvalid_0's rmse: 1.59662\n",
      "[64]\tvalid_0's rmse: 1.59538\n",
      "[65]\tvalid_0's rmse: 1.59342\n",
      "[66]\tvalid_0's rmse: 1.59178\n",
      "[67]\tvalid_0's rmse: 1.59028\n",
      "[68]\tvalid_0's rmse: 1.58893\n",
      "[69]\tvalid_0's rmse: 1.58725\n",
      "[70]\tvalid_0's rmse: 1.58567\n",
      "[71]\tvalid_0's rmse: 1.58421\n",
      "[72]\tvalid_0's rmse: 1.58242\n",
      "[73]\tvalid_0's rmse: 1.58112\n",
      "[74]\tvalid_0's rmse: 1.57947\n",
      "[75]\tvalid_0's rmse: 1.57788\n",
      "[76]\tvalid_0's rmse: 1.57646\n",
      "[77]\tvalid_0's rmse: 1.57497\n",
      "[78]\tvalid_0's rmse: 1.57354\n",
      "[79]\tvalid_0's rmse: 1.57238\n",
      "[80]\tvalid_0's rmse: 1.57079\n",
      "[81]\tvalid_0's rmse: 1.5691\n",
      "[82]\tvalid_0's rmse: 1.56732\n",
      "[83]\tvalid_0's rmse: 1.56622\n",
      "[84]\tvalid_0's rmse: 1.56494\n",
      "[85]\tvalid_0's rmse: 1.56356\n",
      "[86]\tvalid_0's rmse: 1.56238\n",
      "[87]\tvalid_0's rmse: 1.56077\n",
      "[88]\tvalid_0's rmse: 1.55941\n",
      "[89]\tvalid_0's rmse: 1.55785\n",
      "[90]\tvalid_0's rmse: 1.55657\n",
      "[91]\tvalid_0's rmse: 1.55542\n",
      "[92]\tvalid_0's rmse: 1.55398\n",
      "[93]\tvalid_0's rmse: 1.55235\n",
      "[94]\tvalid_0's rmse: 1.55155\n",
      "[95]\tvalid_0's rmse: 1.55062\n",
      "[96]\tvalid_0's rmse: 1.54936\n",
      "[97]\tvalid_0's rmse: 1.5482\n",
      "[98]\tvalid_0's rmse: 1.54737\n",
      "[99]\tvalid_0's rmse: 1.54605\n",
      "[100]\tvalid_0's rmse: 1.54509\n",
      "[101]\tvalid_0's rmse: 1.54377\n",
      "[102]\tvalid_0's rmse: 1.54239\n",
      "[103]\tvalid_0's rmse: 1.5413\n",
      "[104]\tvalid_0's rmse: 1.54032\n",
      "[105]\tvalid_0's rmse: 1.53934\n",
      "[106]\tvalid_0's rmse: 1.53794\n",
      "[107]\tvalid_0's rmse: 1.53706\n",
      "[108]\tvalid_0's rmse: 1.53599\n",
      "[109]\tvalid_0's rmse: 1.53464\n",
      "[110]\tvalid_0's rmse: 1.53354\n",
      "[111]\tvalid_0's rmse: 1.53237\n",
      "[112]\tvalid_0's rmse: 1.53113\n",
      "[113]\tvalid_0's rmse: 1.52991\n",
      "[114]\tvalid_0's rmse: 1.52893\n",
      "[115]\tvalid_0's rmse: 1.52804\n",
      "[116]\tvalid_0's rmse: 1.5271\n",
      "[117]\tvalid_0's rmse: 1.52613\n",
      "[118]\tvalid_0's rmse: 1.5249\n",
      "[119]\tvalid_0's rmse: 1.52389\n",
      "[120]\tvalid_0's rmse: 1.52282\n",
      "[121]\tvalid_0's rmse: 1.52169\n",
      "[122]\tvalid_0's rmse: 1.52052\n",
      "[123]\tvalid_0's rmse: 1.51939\n",
      "[124]\tvalid_0's rmse: 1.51838\n",
      "[125]\tvalid_0's rmse: 1.51744\n",
      "[126]\tvalid_0's rmse: 1.51652\n",
      "[127]\tvalid_0's rmse: 1.51569\n",
      "[128]\tvalid_0's rmse: 1.5145\n",
      "[129]\tvalid_0's rmse: 1.51382\n",
      "[130]\tvalid_0's rmse: 1.51286\n",
      "[131]\tvalid_0's rmse: 1.51203\n",
      "[132]\tvalid_0's rmse: 1.51125\n",
      "[133]\tvalid_0's rmse: 1.51062\n",
      "[134]\tvalid_0's rmse: 1.50979\n",
      "[135]\tvalid_0's rmse: 1.50866\n",
      "[136]\tvalid_0's rmse: 1.50781\n",
      "[137]\tvalid_0's rmse: 1.50702\n",
      "[138]\tvalid_0's rmse: 1.50611\n",
      "[139]\tvalid_0's rmse: 1.50517\n",
      "[140]\tvalid_0's rmse: 1.50449\n",
      "[141]\tvalid_0's rmse: 1.5038\n",
      "[142]\tvalid_0's rmse: 1.50301\n",
      "[143]\tvalid_0's rmse: 1.50204\n",
      "[144]\tvalid_0's rmse: 1.50125\n",
      "[145]\tvalid_0's rmse: 1.50036\n",
      "[146]\tvalid_0's rmse: 1.49959\n",
      "[147]\tvalid_0's rmse: 1.49862\n",
      "[148]\tvalid_0's rmse: 1.49785\n",
      "[149]\tvalid_0's rmse: 1.49711\n",
      "[150]\tvalid_0's rmse: 1.49635\n",
      "[151]\tvalid_0's rmse: 1.49558\n",
      "[152]\tvalid_0's rmse: 1.49496\n",
      "[153]\tvalid_0's rmse: 1.49456\n",
      "[154]\tvalid_0's rmse: 1.49393\n",
      "[155]\tvalid_0's rmse: 1.49345\n",
      "[156]\tvalid_0's rmse: 1.49256\n",
      "[157]\tvalid_0's rmse: 1.4919\n",
      "[158]\tvalid_0's rmse: 1.49086\n",
      "[159]\tvalid_0's rmse: 1.49025\n",
      "[160]\tvalid_0's rmse: 1.48936\n",
      "[161]\tvalid_0's rmse: 1.48865\n",
      "[162]\tvalid_0's rmse: 1.48779\n",
      "[163]\tvalid_0's rmse: 1.48719\n",
      "[164]\tvalid_0's rmse: 1.48634\n",
      "[165]\tvalid_0's rmse: 1.48574\n",
      "[166]\tvalid_0's rmse: 1.48514\n",
      "[167]\tvalid_0's rmse: 1.48457\n",
      "[168]\tvalid_0's rmse: 1.4841\n",
      "[169]\tvalid_0's rmse: 1.48346\n",
      "[170]\tvalid_0's rmse: 1.48289\n",
      "[171]\tvalid_0's rmse: 1.48219\n",
      "[172]\tvalid_0's rmse: 1.48134\n",
      "[173]\tvalid_0's rmse: 1.48068\n",
      "[174]\tvalid_0's rmse: 1.47996\n",
      "[175]\tvalid_0's rmse: 1.47922\n",
      "[176]\tvalid_0's rmse: 1.47845\n",
      "[177]\tvalid_0's rmse: 1.47801\n",
      "[178]\tvalid_0's rmse: 1.47736\n",
      "[179]\tvalid_0's rmse: 1.47678\n",
      "[180]\tvalid_0's rmse: 1.47616\n",
      "[181]\tvalid_0's rmse: 1.4754\n",
      "[182]\tvalid_0's rmse: 1.47479\n",
      "[183]\tvalid_0's rmse: 1.47397\n",
      "[184]\tvalid_0's rmse: 1.47328\n",
      "[185]\tvalid_0's rmse: 1.47291\n",
      "[186]\tvalid_0's rmse: 1.4722\n",
      "[187]\tvalid_0's rmse: 1.47168\n",
      "[188]\tvalid_0's rmse: 1.47111\n",
      "[189]\tvalid_0's rmse: 1.47068\n",
      "[190]\tvalid_0's rmse: 1.47002\n",
      "[191]\tvalid_0's rmse: 1.46952\n",
      "[192]\tvalid_0's rmse: 1.46894\n",
      "[193]\tvalid_0's rmse: 1.46849\n",
      "[194]\tvalid_0's rmse: 1.46795\n",
      "[195]\tvalid_0's rmse: 1.46748\n",
      "[196]\tvalid_0's rmse: 1.46697\n",
      "[197]\tvalid_0's rmse: 1.46654\n",
      "[198]\tvalid_0's rmse: 1.46611\n",
      "[199]\tvalid_0's rmse: 1.46564\n",
      "[200]\tvalid_0's rmse: 1.465\n",
      "[201]\tvalid_0's rmse: 1.46468\n",
      "[202]\tvalid_0's rmse: 1.46418\n",
      "[203]\tvalid_0's rmse: 1.46354\n",
      "[204]\tvalid_0's rmse: 1.46303\n",
      "[205]\tvalid_0's rmse: 1.46274\n",
      "[206]\tvalid_0's rmse: 1.46254\n",
      "[207]\tvalid_0's rmse: 1.46228\n",
      "[208]\tvalid_0's rmse: 1.46178\n",
      "[209]\tvalid_0's rmse: 1.46131\n",
      "[210]\tvalid_0's rmse: 1.46072\n",
      "[211]\tvalid_0's rmse: 1.46035\n",
      "[212]\tvalid_0's rmse: 1.45988\n",
      "[213]\tvalid_0's rmse: 1.4594\n",
      "[214]\tvalid_0's rmse: 1.45886\n",
      "[215]\tvalid_0's rmse: 1.45832\n",
      "[216]\tvalid_0's rmse: 1.45779\n",
      "[217]\tvalid_0's rmse: 1.45749\n",
      "[218]\tvalid_0's rmse: 1.45695\n",
      "[219]\tvalid_0's rmse: 1.45652\n",
      "[220]\tvalid_0's rmse: 1.4558\n",
      "[221]\tvalid_0's rmse: 1.45532\n",
      "[222]\tvalid_0's rmse: 1.45496\n",
      "[223]\tvalid_0's rmse: 1.45461\n",
      "[224]\tvalid_0's rmse: 1.45426\n",
      "[225]\tvalid_0's rmse: 1.45369\n",
      "[226]\tvalid_0's rmse: 1.45318\n",
      "[227]\tvalid_0's rmse: 1.45269\n",
      "[228]\tvalid_0's rmse: 1.45204\n",
      "[229]\tvalid_0's rmse: 1.45144\n",
      "[230]\tvalid_0's rmse: 1.45085\n",
      "[231]\tvalid_0's rmse: 1.45051\n",
      "[232]\tvalid_0's rmse: 1.45012\n",
      "[233]\tvalid_0's rmse: 1.44963\n",
      "[234]\tvalid_0's rmse: 1.44921\n",
      "[235]\tvalid_0's rmse: 1.44878\n",
      "[236]\tvalid_0's rmse: 1.44864\n",
      "[237]\tvalid_0's rmse: 1.44836\n",
      "[238]\tvalid_0's rmse: 1.44807\n",
      "[239]\tvalid_0's rmse: 1.44764\n",
      "[240]\tvalid_0's rmse: 1.44739\n",
      "[241]\tvalid_0's rmse: 1.447\n",
      "[242]\tvalid_0's rmse: 1.44671\n",
      "[243]\tvalid_0's rmse: 1.44616\n",
      "[244]\tvalid_0's rmse: 1.44575\n",
      "[245]\tvalid_0's rmse: 1.44524\n",
      "[246]\tvalid_0's rmse: 1.44508\n",
      "[247]\tvalid_0's rmse: 1.44468\n",
      "[248]\tvalid_0's rmse: 1.44424\n",
      "[249]\tvalid_0's rmse: 1.44377\n",
      "[250]\tvalid_0's rmse: 1.44321\n",
      "[251]\tvalid_0's rmse: 1.44261\n",
      "[252]\tvalid_0's rmse: 1.4423\n",
      "[253]\tvalid_0's rmse: 1.442\n",
      "[254]\tvalid_0's rmse: 1.44177\n",
      "[255]\tvalid_0's rmse: 1.44125\n",
      "[256]\tvalid_0's rmse: 1.44102\n",
      "[257]\tvalid_0's rmse: 1.44071\n",
      "[258]\tvalid_0's rmse: 1.44052\n",
      "[259]\tvalid_0's rmse: 1.4401\n",
      "[260]\tvalid_0's rmse: 1.43999\n",
      "[261]\tvalid_0's rmse: 1.43977\n",
      "[262]\tvalid_0's rmse: 1.43965\n",
      "[263]\tvalid_0's rmse: 1.43949\n",
      "[264]\tvalid_0's rmse: 1.43911\n",
      "[265]\tvalid_0's rmse: 1.43881\n",
      "[266]\tvalid_0's rmse: 1.43867\n",
      "[267]\tvalid_0's rmse: 1.43833\n",
      "[268]\tvalid_0's rmse: 1.438\n",
      "[269]\tvalid_0's rmse: 1.43767\n",
      "[270]\tvalid_0's rmse: 1.43727\n",
      "[271]\tvalid_0's rmse: 1.43687\n",
      "[272]\tvalid_0's rmse: 1.43674\n",
      "[273]\tvalid_0's rmse: 1.43654\n",
      "[274]\tvalid_0's rmse: 1.43614\n",
      "[275]\tvalid_0's rmse: 1.43588\n",
      "[276]\tvalid_0's rmse: 1.43555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[277]\tvalid_0's rmse: 1.43525\n",
      "[278]\tvalid_0's rmse: 1.43531\n",
      "[279]\tvalid_0's rmse: 1.43532\n",
      "[280]\tvalid_0's rmse: 1.43521\n",
      "[281]\tvalid_0's rmse: 1.4347\n",
      "[282]\tvalid_0's rmse: 1.43434\n",
      "[283]\tvalid_0's rmse: 1.43388\n",
      "[284]\tvalid_0's rmse: 1.43373\n",
      "[285]\tvalid_0's rmse: 1.43341\n",
      "[286]\tvalid_0's rmse: 1.43306\n",
      "[287]\tvalid_0's rmse: 1.43251\n",
      "[288]\tvalid_0's rmse: 1.43233\n",
      "[289]\tvalid_0's rmse: 1.43217\n",
      "[290]\tvalid_0's rmse: 1.43191\n",
      "[291]\tvalid_0's rmse: 1.43167\n",
      "[292]\tvalid_0's rmse: 1.4315\n",
      "[293]\tvalid_0's rmse: 1.43156\n",
      "[294]\tvalid_0's rmse: 1.43136\n",
      "[295]\tvalid_0's rmse: 1.43105\n",
      "[296]\tvalid_0's rmse: 1.43092\n",
      "[297]\tvalid_0's rmse: 1.43081\n",
      "[298]\tvalid_0's rmse: 1.4306\n",
      "[299]\tvalid_0's rmse: 1.43025\n",
      "[300]\tvalid_0's rmse: 1.43022\n",
      "[301]\tvalid_0's rmse: 1.43001\n",
      "[302]\tvalid_0's rmse: 1.42978\n",
      "[303]\tvalid_0's rmse: 1.42938\n",
      "[304]\tvalid_0's rmse: 1.42922\n",
      "[305]\tvalid_0's rmse: 1.42901\n",
      "[306]\tvalid_0's rmse: 1.42899\n",
      "[307]\tvalid_0's rmse: 1.4288\n",
      "[308]\tvalid_0's rmse: 1.42851\n",
      "[309]\tvalid_0's rmse: 1.42823\n",
      "[310]\tvalid_0's rmse: 1.42813\n",
      "[311]\tvalid_0's rmse: 1.42789\n",
      "[312]\tvalid_0's rmse: 1.42782\n",
      "[313]\tvalid_0's rmse: 1.4276\n",
      "[314]\tvalid_0's rmse: 1.42737\n",
      "[315]\tvalid_0's rmse: 1.42722\n",
      "[316]\tvalid_0's rmse: 1.42682\n",
      "[317]\tvalid_0's rmse: 1.42665\n",
      "[318]\tvalid_0's rmse: 1.42641\n",
      "[319]\tvalid_0's rmse: 1.4263\n",
      "[320]\tvalid_0's rmse: 1.4263\n",
      "[321]\tvalid_0's rmse: 1.426\n",
      "[322]\tvalid_0's rmse: 1.42582\n",
      "[323]\tvalid_0's rmse: 1.42545\n",
      "[324]\tvalid_0's rmse: 1.42502\n",
      "[325]\tvalid_0's rmse: 1.42494\n",
      "[326]\tvalid_0's rmse: 1.42459\n",
      "[327]\tvalid_0's rmse: 1.42447\n",
      "[328]\tvalid_0's rmse: 1.42433\n",
      "[329]\tvalid_0's rmse: 1.42419\n",
      "[330]\tvalid_0's rmse: 1.42405\n",
      "[331]\tvalid_0's rmse: 1.42373\n",
      "[332]\tvalid_0's rmse: 1.4236\n",
      "[333]\tvalid_0's rmse: 1.42333\n",
      "[334]\tvalid_0's rmse: 1.42311\n",
      "[335]\tvalid_0's rmse: 1.42283\n",
      "[336]\tvalid_0's rmse: 1.4228\n",
      "[337]\tvalid_0's rmse: 1.42261\n",
      "[338]\tvalid_0's rmse: 1.42244\n",
      "[339]\tvalid_0's rmse: 1.42238\n",
      "[340]\tvalid_0's rmse: 1.42213\n",
      "[341]\tvalid_0's rmse: 1.42212\n",
      "[342]\tvalid_0's rmse: 1.42187\n",
      "[343]\tvalid_0's rmse: 1.42152\n",
      "[344]\tvalid_0's rmse: 1.42155\n",
      "[345]\tvalid_0's rmse: 1.4215\n",
      "[346]\tvalid_0's rmse: 1.42131\n",
      "[347]\tvalid_0's rmse: 1.42117\n",
      "[348]\tvalid_0's rmse: 1.42101\n",
      "[349]\tvalid_0's rmse: 1.42085\n",
      "[350]\tvalid_0's rmse: 1.42071\n",
      "[351]\tvalid_0's rmse: 1.42064\n",
      "[352]\tvalid_0's rmse: 1.42051\n",
      "[353]\tvalid_0's rmse: 1.42032\n",
      "[354]\tvalid_0's rmse: 1.42026\n",
      "[355]\tvalid_0's rmse: 1.42018\n",
      "[356]\tvalid_0's rmse: 1.42004\n",
      "[357]\tvalid_0's rmse: 1.41983\n",
      "[358]\tvalid_0's rmse: 1.41966\n",
      "[359]\tvalid_0's rmse: 1.41955\n",
      "[360]\tvalid_0's rmse: 1.4193\n",
      "[361]\tvalid_0's rmse: 1.41933\n",
      "[362]\tvalid_0's rmse: 1.41922\n",
      "[363]\tvalid_0's rmse: 1.41904\n",
      "[364]\tvalid_0's rmse: 1.41896\n",
      "[365]\tvalid_0's rmse: 1.41868\n",
      "[366]\tvalid_0's rmse: 1.41849\n",
      "[367]\tvalid_0's rmse: 1.41856\n",
      "[368]\tvalid_0's rmse: 1.41835\n",
      "[369]\tvalid_0's rmse: 1.41827\n",
      "[370]\tvalid_0's rmse: 1.4182\n",
      "[371]\tvalid_0's rmse: 1.41801\n",
      "[372]\tvalid_0's rmse: 1.41803\n",
      "[373]\tvalid_0's rmse: 1.41791\n",
      "[374]\tvalid_0's rmse: 1.41784\n",
      "[375]\tvalid_0's rmse: 1.41788\n",
      "[376]\tvalid_0's rmse: 1.41791\n",
      "[377]\tvalid_0's rmse: 1.41795\n",
      "[378]\tvalid_0's rmse: 1.41785\n",
      "[379]\tvalid_0's rmse: 1.4175\n",
      "[380]\tvalid_0's rmse: 1.41745\n",
      "[381]\tvalid_0's rmse: 1.41738\n",
      "[382]\tvalid_0's rmse: 1.41725\n",
      "[383]\tvalid_0's rmse: 1.4172\n",
      "[384]\tvalid_0's rmse: 1.41692\n",
      "[385]\tvalid_0's rmse: 1.41694\n",
      "[386]\tvalid_0's rmse: 1.41699\n",
      "[387]\tvalid_0's rmse: 1.417\n",
      "[388]\tvalid_0's rmse: 1.41695\n",
      "[389]\tvalid_0's rmse: 1.41686\n",
      "[390]\tvalid_0's rmse: 1.41677\n",
      "[391]\tvalid_0's rmse: 1.41648\n",
      "[392]\tvalid_0's rmse: 1.41624\n",
      "[393]\tvalid_0's rmse: 1.41617\n",
      "[394]\tvalid_0's rmse: 1.41591\n",
      "[395]\tvalid_0's rmse: 1.41586\n",
      "[396]\tvalid_0's rmse: 1.41573\n",
      "[397]\tvalid_0's rmse: 1.4157\n",
      "[398]\tvalid_0's rmse: 1.41571\n",
      "[399]\tvalid_0's rmse: 1.4156\n",
      "[400]\tvalid_0's rmse: 1.41547\n",
      "[401]\tvalid_0's rmse: 1.41528\n",
      "[402]\tvalid_0's rmse: 1.41524\n",
      "[403]\tvalid_0's rmse: 1.41516\n",
      "[404]\tvalid_0's rmse: 1.415\n",
      "[405]\tvalid_0's rmse: 1.41491\n",
      "[406]\tvalid_0's rmse: 1.41483\n",
      "[407]\tvalid_0's rmse: 1.41477\n",
      "[408]\tvalid_0's rmse: 1.41477\n",
      "[409]\tvalid_0's rmse: 1.41475\n",
      "[410]\tvalid_0's rmse: 1.41462\n",
      "[411]\tvalid_0's rmse: 1.41448\n",
      "[412]\tvalid_0's rmse: 1.41446\n",
      "[413]\tvalid_0's rmse: 1.41435\n",
      "[414]\tvalid_0's rmse: 1.41429\n",
      "[415]\tvalid_0's rmse: 1.41418\n",
      "[416]\tvalid_0's rmse: 1.41402\n",
      "[417]\tvalid_0's rmse: 1.41386\n",
      "[418]\tvalid_0's rmse: 1.41391\n",
      "[419]\tvalid_0's rmse: 1.41406\n",
      "[420]\tvalid_0's rmse: 1.41404\n",
      "[421]\tvalid_0's rmse: 1.41395\n",
      "[422]\tvalid_0's rmse: 1.41367\n",
      "[423]\tvalid_0's rmse: 1.41355\n",
      "[424]\tvalid_0's rmse: 1.41333\n",
      "[425]\tvalid_0's rmse: 1.4132\n",
      "[426]\tvalid_0's rmse: 1.41316\n",
      "[427]\tvalid_0's rmse: 1.41309\n",
      "[428]\tvalid_0's rmse: 1.41312\n",
      "[429]\tvalid_0's rmse: 1.41311\n",
      "[430]\tvalid_0's rmse: 1.41305\n",
      "[431]\tvalid_0's rmse: 1.41309\n",
      "[432]\tvalid_0's rmse: 1.41305\n",
      "[433]\tvalid_0's rmse: 1.41309\n",
      "[434]\tvalid_0's rmse: 1.41305\n",
      "[435]\tvalid_0's rmse: 1.41306\n",
      "[436]\tvalid_0's rmse: 1.41294\n",
      "[437]\tvalid_0's rmse: 1.41295\n",
      "[438]\tvalid_0's rmse: 1.41288\n",
      "[439]\tvalid_0's rmse: 1.41281\n",
      "[440]\tvalid_0's rmse: 1.41275\n",
      "[441]\tvalid_0's rmse: 1.41277\n",
      "[442]\tvalid_0's rmse: 1.41269\n",
      "[443]\tvalid_0's rmse: 1.41247\n",
      "[444]\tvalid_0's rmse: 1.4124\n",
      "[445]\tvalid_0's rmse: 1.41214\n",
      "[446]\tvalid_0's rmse: 1.41204\n",
      "[447]\tvalid_0's rmse: 1.41195\n",
      "[448]\tvalid_0's rmse: 1.41178\n",
      "[449]\tvalid_0's rmse: 1.41165\n",
      "[450]\tvalid_0's rmse: 1.41165\n",
      "[451]\tvalid_0's rmse: 1.41156\n",
      "[452]\tvalid_0's rmse: 1.41141\n",
      "[453]\tvalid_0's rmse: 1.41115\n",
      "[454]\tvalid_0's rmse: 1.41109\n",
      "[455]\tvalid_0's rmse: 1.41082\n",
      "[456]\tvalid_0's rmse: 1.41076\n",
      "[457]\tvalid_0's rmse: 1.41089\n",
      "[458]\tvalid_0's rmse: 1.4108\n",
      "[459]\tvalid_0's rmse: 1.41081\n",
      "[460]\tvalid_0's rmse: 1.41087\n",
      "[461]\tvalid_0's rmse: 1.41082\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid_0's rmse: 1.41076\n",
      "Start predicting...\n",
      "The rmse of prediction is: 1.4107575862807875\n"
     ]
    }
   ],
   "source": [
    "X=train[train.columns[2:]]\n",
    "y=np.log1p(train['target'])\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=203)\n",
    "\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return abs(np.sqrt(np.mean((y_pred - y_true)**2))) \n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'gamma',\n",
    "    'metric': {'rmse'},\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.008,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 4,\n",
    "    'max_depth': -1,\n",
    "    'reg_alpha': 0.3,\n",
    "    'reg_lambda': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'zero_as_missing': True,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From one of the successful ker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.1\n",
      "Optimal Round: 48\n",
      "Optimal Score: 1.4591752720018802 + 0.04680836418661446\n",
      "###########################################################################################\n",
      "Learning Rate:  0.01\n",
      "[200]\tcv_agg's rmse: 1.46691 + 0.0411651\n",
      "[400]\tcv_agg's rmse: 1.43651 + 0.0468959\n",
      "[600]\tcv_agg's rmse: 1.4336 + 0.0501861\n",
      "Optimal Round: 551\n",
      "Optimal Score: 1.4333652915263275 + 0.04992601520324436\n",
      "###########################################################################################\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "learning_rates = [0.012,0.008]\n",
    "for param in learning_rates:\n",
    "    print(\"Learning Rate: \", param)\n",
    "    modelstart= time.time()\n",
    "    params[\"learning_rate\"] = param\n",
    "    # Find Optimal Parameters / Boosting Rounds\n",
    "    lgb_cv = lgb.cv(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        stratified=False,\n",
    "        nfold = 5,\n",
    "        verbose_eval=200,\n",
    "        seed = 23,\n",
    "        early_stopping_rounds=75)\n",
    "\n",
    "    optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
    "    best_cv_score = min(lgb_cv['rmse-mean'])\n",
    "\n",
    "    print(\"Optimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "        optimal_rounds,best_cv_score,lgb_cv['rmse-stdv'][optimal_rounds]))\n",
    "    print(\"###########################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train[train.columns[2:]]\n",
    "y_train=np.log1p(train['target'])\n",
    "\n",
    "x_test=test[x_train.columns]\n",
    "\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return abs(K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)))\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'gamma',\n",
    "    'metric': {'rmse'},\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.008,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 4,\n",
    "    'max_depth': -1,\n",
    "    'reg_alpha': 0.3,\n",
    "    'reg_lambda': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'zero_as_missing': True,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000)\n",
    "\n",
    "y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID        target\n",
      "0  000137c73  1.627427e+06\n",
      "1  00021489f  1.977776e+06\n",
      "2  0004d7953  3.926302e+06\n",
      "3  00056a333  7.194788e+06\n",
      "4  00056d8eb  1.977776e+06\n"
     ]
    }
   ],
   "source": [
    "predictions=pd.DataFrame({'ID':test['ID'],'target':np.expm1(y_pred)})\n",
    "print(predictions.head())\n",
    "predictions.to_csv('pred_pure_lightgbm.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
